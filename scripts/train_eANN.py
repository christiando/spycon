# %%
import numpy
import spycon
from spycon import coninf, load_test
from spycon.coninf import setup_ensemble

model_path = "../data/nn_models/"

# Name of tests that are used for training
train_test_names = [
    "ren_simulation_2602_cell3VC_340_20",
    "ren_simulation_2602_cell3VC_340_16",
    "ren_simulation_2602_cell3VC_360_8",
    "ren_simulation_2602_cell3VC_420_8",
    "ren_simulation_2602_cell3VC_400_18",
]


num_of_neurons = 100  # Number of neurons in test
t_stop = 3600  # Length of test in seconds
num_exc_neurons = num_of_neurons // 2  # Number of excitatory neurons in test

num_cores = 4  # Number of cores used for parallelization
num_iter = 5  # Number of iterations for each test (random subset of neurons)

# load the base methods as dictionary
coninf_dict, model_name = setup_ensemble.get_eann_coninf_dict(num_cores=num_cores)

# Generate the tests and put them in a list
spycon_tests = []

for test_name in train_test_names:
    for iiter in range(5):
        exc_neurons, inh_neurons = numpy.arange(0, 150), numpy.arange(150, 300)
        numpy.random.shuffle(exc_neurons), numpy.random.shuffle(inh_neurons)
        subset = numpy.concatenate(
            [
                exc_neurons[:num_exc_neurons],
                inh_neurons[: num_of_neurons - num_exc_neurons],
            ]
        )
        test = load_test(
            test_name,
            params={"T_stop": t_stop, "subset": subset},
            path="../data/gt_data/simulated_gt/",
        )
        spycon_tests.append(test)

# Training set is generated by iterating over tests and methods and concatinating the results
# This takes some time (rather run on a cluster with sufficient resources)
input_features, labels = coninf.sci_ensemble.load_train_dataset(
    spycon_tests, coninf_dict
)
# Save the training set
numpy.savez(model_path + model_name + "_trainset.npz", X=input_features, y=labels)
# Load the training set if already precomputed
# trainset = numpy.load(model_path + model_name + "_trainset.npz")
# input_features = trainset["X"]
# labels = trainset["y"]

# Network is trained
coninf.sci_ensemble.train_network(
    model_name, input_features, labels, model_path, save_training_models=True
)

# %%
